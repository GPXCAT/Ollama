version: "3.3"
services:
  ollama:
    image: ollama/ollama
    restart: unless-stopped
    volumes:
      - ./data/ollama:/root/.ollama
    ports:
      - 11434:11434
    networks:
      - ollama-net
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    volumes:
      - ./data/open-webui:/app/backend/data
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
    ports:
      - 8080:8080
    networks:
      - ollama-net

  anythingllm:
    image: mintplexlabs/anythingllm
    container_name: anythingllm
    volumes:
      - ./data/anythingllm/storage:/app/server/storage
      - ./data/anythingllm/.env:/app/server/.env
    environment:
      - STORAGE_DIR=/app/server/storage
    cap_add:
      - SYS_ADMIN
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    ports:
      - 3001:3001
    networks:
      - ollama-net

networks:
  ollama-net:
